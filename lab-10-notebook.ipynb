{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 10: Fashion MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "author: Alejandra Arias\n",
    "date: December 6, 2024\n",
    "embed-resources: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# standard imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# sklearn data\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# sklearn models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# sklearn metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# pytorch imports\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26.4M/26.4M [01:08<00:00, 388kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29.5k/29.5k [00:00<00:00, 102kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.42M/4.42M [00:05<00:00, 812kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.15k/5.15k [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "\n",
    "# download training data from open datasets\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# download test data from open datasets\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summary statistics\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device for training!\n"
     ]
    }
   ],
   "source": [
    "# visualizations\n",
    "# get cpu, gpu or mps device for training\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(f\"Using {device} device for training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "# define batch size\n",
    "batch_size = 64\n",
    "\n",
    "# create train data loader\n",
    "train_dataloader = DataLoader(\n",
    "    training_data,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "# create test data loader\n",
    "test_dataloader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "# check data shapes\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "# send model to compute device\n",
    "model = NeuralNetwork().to(device)\n",
    "\n",
    "# check model structure\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define train loop\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define test loop\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.587142  [   64/60000]\n",
      "loss: 0.684800  [ 6464/60000]\n",
      "loss: 0.469634  [12864/60000]\n",
      "loss: 0.702026  [19264/60000]\n",
      "loss: 0.635299  [25664/60000]\n",
      "loss: 0.607768  [32064/60000]\n",
      "loss: 0.654702  [38464/60000]\n",
      "loss: 0.700093  [44864/60000]\n",
      "loss: 0.687465  [51264/60000]\n",
      "loss: 0.628154  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.629011 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.571699  [   64/60000]\n",
      "loss: 0.669896  [ 6464/60000]\n",
      "loss: 0.457732  [12864/60000]\n",
      "loss: 0.691034  [19264/60000]\n",
      "loss: 0.627558  [25664/60000]\n",
      "loss: 0.599772  [32064/60000]\n",
      "loss: 0.641573  [38464/60000]\n",
      "loss: 0.693417  [44864/60000]\n",
      "loss: 0.680301  [51264/60000]\n",
      "loss: 0.617719  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 0.618596 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.557627  [   64/60000]\n",
      "loss: 0.656138  [ 6464/60000]\n",
      "loss: 0.446768  [12864/60000]\n",
      "loss: 0.680701  [19264/60000]\n",
      "loss: 0.620416  [25664/60000]\n",
      "loss: 0.592572  [32064/60000]\n",
      "loss: 0.629485  [38464/60000]\n",
      "loss: 0.687660  [44864/60000]\n",
      "loss: 0.674250  [51264/60000]\n",
      "loss: 0.607948  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.609004 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.544701  [   64/60000]\n",
      "loss: 0.643453  [ 6464/60000]\n",
      "loss: 0.436723  [12864/60000]\n",
      "loss: 0.670973  [19264/60000]\n",
      "loss: 0.613742  [25664/60000]\n",
      "loss: 0.586010  [32064/60000]\n",
      "loss: 0.618324  [38464/60000]\n",
      "loss: 0.682753  [44864/60000]\n",
      "loss: 0.669135  [51264/60000]\n",
      "loss: 0.598695  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.600159 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.532875  [   64/60000]\n",
      "loss: 0.631752  [ 6464/60000]\n",
      "loss: 0.427487  [12864/60000]\n",
      "loss: 0.661765  [19264/60000]\n",
      "loss: 0.607404  [25664/60000]\n",
      "loss: 0.579942  [32064/60000]\n",
      "loss: 0.608012  [38464/60000]\n",
      "loss: 0.678636  [44864/60000]\n",
      "loss: 0.664822  [51264/60000]\n",
      "loss: 0.589896  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.591981 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.521888  [   64/60000]\n",
      "loss: 0.620884  [ 6464/60000]\n",
      "loss: 0.418926  [12864/60000]\n",
      "loss: 0.653030  [19264/60000]\n",
      "loss: 0.601369  [25664/60000]\n",
      "loss: 0.574287  [32064/60000]\n",
      "loss: 0.598448  [38464/60000]\n",
      "loss: 0.675268  [44864/60000]\n",
      "loss: 0.661152  [51264/60000]\n",
      "loss: 0.581526  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.584409 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.511643  [   64/60000]\n",
      "loss: 0.610837  [ 6464/60000]\n",
      "loss: 0.410992  [12864/60000]\n",
      "loss: 0.644765  [19264/60000]\n",
      "loss: 0.595484  [25664/60000]\n",
      "loss: 0.568936  [32064/60000]\n",
      "loss: 0.589580  [38464/60000]\n",
      "loss: 0.672677  [44864/60000]\n",
      "loss: 0.658014  [51264/60000]\n",
      "loss: 0.573560  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.577387 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.502020  [   64/60000]\n",
      "loss: 0.601492  [ 6464/60000]\n",
      "loss: 0.403583  [12864/60000]\n",
      "loss: 0.636916  [19264/60000]\n",
      "loss: 0.589653  [25664/60000]\n",
      "loss: 0.563880  [32064/60000]\n",
      "loss: 0.581433  [38464/60000]\n",
      "loss: 0.670670  [44864/60000]\n",
      "loss: 0.655192  [51264/60000]\n",
      "loss: 0.565847  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.570866 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.492999  [   64/60000]\n",
      "loss: 0.592819  [ 6464/60000]\n",
      "loss: 0.396654  [12864/60000]\n",
      "loss: 0.629447  [19264/60000]\n",
      "loss: 0.583890  [25664/60000]\n",
      "loss: 0.559103  [32064/60000]\n",
      "loss: 0.573893  [38464/60000]\n",
      "loss: 0.669018  [44864/60000]\n",
      "loss: 0.652695  [51264/60000]\n",
      "loss: 0.558461  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.564797 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.484494  [   64/60000]\n",
      "loss: 0.584768  [ 6464/60000]\n",
      "loss: 0.390159  [12864/60000]\n",
      "loss: 0.622394  [19264/60000]\n",
      "loss: 0.578163  [25664/60000]\n",
      "loss: 0.554570  [32064/60000]\n",
      "loss: 0.566880  [38464/60000]\n",
      "loss: 0.667794  [44864/60000]\n",
      "loss: 0.650344  [51264/60000]\n",
      "loss: 0.551302  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.559131 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.476486  [   64/60000]\n",
      "loss: 0.577277  [ 6464/60000]\n",
      "loss: 0.384085  [12864/60000]\n",
      "loss: 0.615695  [19264/60000]\n",
      "loss: 0.572500  [25664/60000]\n",
      "loss: 0.550155  [32064/60000]\n",
      "loss: 0.560341  [38464/60000]\n",
      "loss: 0.666910  [44864/60000]\n",
      "loss: 0.648214  [51264/60000]\n",
      "loss: 0.544338  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.553835 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.468870  [   64/60000]\n",
      "loss: 0.570334  [ 6464/60000]\n",
      "loss: 0.378366  [12864/60000]\n",
      "loss: 0.609296  [19264/60000]\n",
      "loss: 0.566899  [25664/60000]\n",
      "loss: 0.545838  [32064/60000]\n",
      "loss: 0.554231  [38464/60000]\n",
      "loss: 0.666372  [44864/60000]\n",
      "loss: 0.646172  [51264/60000]\n",
      "loss: 0.537586  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.548878 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.461551  [   64/60000]\n",
      "loss: 0.563912  [ 6464/60000]\n",
      "loss: 0.372955  [12864/60000]\n",
      "loss: 0.603152  [19264/60000]\n",
      "loss: 0.561380  [25664/60000]\n",
      "loss: 0.541537  [32064/60000]\n",
      "loss: 0.548588  [38464/60000]\n",
      "loss: 0.666059  [44864/60000]\n",
      "loss: 0.644177  [51264/60000]\n",
      "loss: 0.530999  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.544229 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.454565  [   64/60000]\n",
      "loss: 0.557903  [ 6464/60000]\n",
      "loss: 0.367863  [12864/60000]\n",
      "loss: 0.597294  [19264/60000]\n",
      "loss: 0.555939  [25664/60000]\n",
      "loss: 0.537296  [32064/60000]\n",
      "loss: 0.543383  [38464/60000]\n",
      "loss: 0.666008  [44864/60000]\n",
      "loss: 0.642250  [51264/60000]\n",
      "loss: 0.524552  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.539859 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.447861  [   64/60000]\n",
      "loss: 0.552351  [ 6464/60000]\n",
      "loss: 0.363072  [12864/60000]\n",
      "loss: 0.591697  [19264/60000]\n",
      "loss: 0.550505  [25664/60000]\n",
      "loss: 0.533069  [32064/60000]\n",
      "loss: 0.538580  [38464/60000]\n",
      "loss: 0.666039  [44864/60000]\n",
      "loss: 0.640325  [51264/60000]\n",
      "loss: 0.518317  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.535742 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.441425  [   64/60000]\n",
      "loss: 0.547138  [ 6464/60000]\n",
      "loss: 0.358497  [12864/60000]\n",
      "loss: 0.586353  [19264/60000]\n",
      "loss: 0.545166  [25664/60000]\n",
      "loss: 0.528914  [32064/60000]\n",
      "loss: 0.534085  [38464/60000]\n",
      "loss: 0.666059  [44864/60000]\n",
      "loss: 0.638444  [51264/60000]\n",
      "loss: 0.512330  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.531845 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.435234  [   64/60000]\n",
      "loss: 0.542327  [ 6464/60000]\n",
      "loss: 0.354148  [12864/60000]\n",
      "loss: 0.581180  [19264/60000]\n",
      "loss: 0.539897  [25664/60000]\n",
      "loss: 0.524857  [32064/60000]\n",
      "loss: 0.529819  [38464/60000]\n",
      "loss: 0.666050  [44864/60000]\n",
      "loss: 0.636539  [51264/60000]\n",
      "loss: 0.506536  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.528179 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.429318  [   64/60000]\n",
      "loss: 0.537881  [ 6464/60000]\n",
      "loss: 0.350048  [12864/60000]\n",
      "loss: 0.576219  [19264/60000]\n",
      "loss: 0.534722  [25664/60000]\n",
      "loss: 0.520887  [32064/60000]\n",
      "loss: 0.525862  [38464/60000]\n",
      "loss: 0.666071  [44864/60000]\n",
      "loss: 0.634600  [51264/60000]\n",
      "loss: 0.501003  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.524719 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.423654  [   64/60000]\n",
      "loss: 0.533738  [ 6464/60000]\n",
      "loss: 0.346199  [12864/60000]\n",
      "loss: 0.571468  [19264/60000]\n",
      "loss: 0.529667  [25664/60000]\n",
      "loss: 0.516965  [32064/60000]\n",
      "loss: 0.522147  [38464/60000]\n",
      "loss: 0.666037  [44864/60000]\n",
      "loss: 0.632688  [51264/60000]\n",
      "loss: 0.495659  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.521441 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.418174  [   64/60000]\n",
      "loss: 0.529848  [ 6464/60000]\n",
      "loss: 0.342542  [12864/60000]\n",
      "loss: 0.566873  [19264/60000]\n",
      "loss: 0.524702  [25664/60000]\n",
      "loss: 0.513061  [32064/60000]\n",
      "loss: 0.518612  [38464/60000]\n",
      "loss: 0.665963  [44864/60000]\n",
      "loss: 0.630743  [51264/60000]\n",
      "loss: 0.490529  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.518329 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "epochs = 20\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report model metrics\n",
    "# convert to TorchScript\n",
    "model_scripted = torch.jit.script(model)\n",
    "\n",
    "# write to disk\n",
    "model_scripted.save(\"fashion-mnist.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxoAAAEOCAYAAAAOmGH2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAgQElEQVR4nO3da4xd1Xk/4HewxzO2x3fGN3yJbCChiVEhxhCLEAJpHSeg2gohUlVB04oPhVYoCkkTqoR8aNPSYpLmRhFpE6IoghQIbdOqCpKNAg3BYDAUimMDnnIxGF/wZYw9tuvz/xDBH2Kz3mP2Gl+fR+LL/PbZe5199l5zXu9hvR2tVqsVAAAAFZ1wuAcAAAAcexQaAABAdQoNAACgOoUGAABQnUIDAACoTqEBAABUp9AAAACqU2gAAADVKTQAAIDqFBpHsb6+vujo6Igbbrih2j7vvffe6OjoiHvvvbfaPoEjkzkEaMo8QolC4xD7/ve/Hx0dHfHwww8f7qEMmttuuy3OPPPM6O7ujt7e3vjjP/7j2Lhx4+EeFhwTjoc55MUXX4xLL700xo4dG6NHj47f+73fi2efffZwDwuOGeYRDpWhh3sAHFtuuummuPLKK+PCCy+MG2+8MV544YX4+7//+3j44YfjwQcfjO7u7sM9ROAI1t/fHx/+8Idj69atce2110ZnZ2d87Wtfiw996EOxcuXKmDBhwuEeInCEM48cORQaVLN79+649tpr47zzzot77rknOjo6IiJi/vz5cfHFF8ctt9wSf/Znf3aYRwkcyb7zne/EmjVrYvny5XHWWWdFRMTChQvjfe97XyxZsiS++tWvHuYRAkc688iRw59OHYF2794dX/7yl+P9739/jBkzJkaOHBkf/OAHY9myZW/7mq997Wsxc+bMGD58eHzoQx+KJ554Yr9tVq1aFZdcckmMHz8+uru7Y+7cufGv//qv6Xhee+21WLVqVfrnT0888URs2bIlPvWpT71RZEREXHTRRdHT0xO33XZbeiyguaN1DomIuOOOO+Kss85648tBRMR73vOeuPDCC+PHP/5x+nqgDvMINSg0jkDbtm2L7373u3H++efH9ddfH1/5yldiw4YNsWDBgli5cuV+2//gBz+Ib3zjG3HVVVfFF7/4xXjiiSfiggsuiPXr17+xzZNPPhnnnHNOPPXUU/GFL3whlixZEiNHjoxFixbFT37yk+J4li9fHqeddlp861vfKm43MDAQERHDhw/fLxs+fHg8+uijsW/fvjbOANDE0TqH7Nu3Lx5//PGYO3fuftm8efPimWeeie3bt7d3EoBGzCPU4E+njkDjxo2Lvr6+GDZs2Bs/u+KKK+I973lPfPOb34x//Md/fMv2Tz/9dKxZsyZOOumkiIj46Ec/GmeffXZcf/31ceONN0ZExNVXXx0zZsyIhx56KLq6uiIi4sorr4xzzz03/vzP/zwWL17ceNynnHJKdHR0xH/913/Fpz/96Td+/qtf/So2bNgQERGvvvqqv42EQXa0ziGbN2+OgYGBmDJlyn7Z6z9bt25dvPvd7258LKDMPEINnmgcgYYMGfLGjb1v377YvHlz7N27N+bOnRuPPPLIftsvWrTojRs74tcV+9lnnx3/8R//ERG/vumWLl0al156aWzfvj02btwYGzdujE2bNsWCBQtizZo18eKLL77teM4///xotVrxla98pTjuE088MS699NK49dZbY8mSJfHss8/GfffdF5/61Keis7MzIiJ27tx5sKcDOEhH6xzy+vzw+heQN3t9IQlzCBwa5hFqUGgcoW699dY4/fTTo7u7OyZMmBC9vb3x7//+77F169b9tj3llFP2+9mpp54afX19EfHrf2VotVrxpS99KXp7e9/y33XXXRcREa+88kqVcd98883xsY99LK655pqYPXt2nHfeeTFnzpy4+OKLIyKip6enynGAsqNxDnn9zy5f/zPMN9u1a9dbtgEGn3mEpvzp1BHohz/8YfzhH/5hLFq0KD73uc/FxIkTY8iQIfHXf/3X8cwzzxz0/l7//yKuueaaWLBgwQG3OfnkkxuN+XVjxoyJf/mXf4nnnnsu+vr6YubMmTFz5syYP39+9Pb2xtixY6scB3h7R+scMn78+Ojq6oqXXnppv+z1n02dOrXxcYCceYQaFBpHoDvuuCNmzZoVd91111tWb3q94v9Na9as2e9nq1evjne9610RETFr1qyIiOjs7IyPfOQj9Qd8ADNmzIgZM2ZERMSWLVtixYoV8YlPfOKQHBuOd0frHHLCCSfEnDlzDthE7MEHH4xZs2bFqFGjBu34wP9nHqEGfzp1BBoyZEhERLRarTd+9uCDD8YDDzxwwO3vvvvut/xd4/Lly+PBBx+MhQsXRkTExIkT4/zzz4+bb775gBX+6/+j9ts5mCXlDuSLX/xi7N27Nz7zmc+8o9cDB+donkMuueSSeOihh97yJeFXv/pVLF26ND75yU+mrwfqMI9Qgycah8k//dM/xX/+53/u9/Orr746Lrroorjrrrti8eLF8fGPfzzWrl0b//AP/xC/9Vu/Ff39/fu95uSTT45zzz03/uRP/iQGBgbi61//ekyYMCE+//nPv7HNt7/97Tj33HNjzpw5ccUVV8SsWbNi/fr18cADD8QLL7wQjz322NuOdfny5fHhD384rrvuuvR/wvqbv/mbeOKJJ+Lss8+OoUOHxt133x0/+9nP4i//8i/fsp410MyxOodceeWVccstt8THP/7xuOaaa6KzszNuvPHGmDRpUnz2s59t/wQBKfMIg67FIfW9732vFRFv+9/zzz/f2rdvX+urX/1qa+bMma2urq7WGWec0frpT3/auvzyy1szZ858Y19r165tRUTr7/7u71pLlixpTZ8+vdXV1dX64Ac/2Hrsscf2O/YzzzzTuuyyy1qTJ09udXZ2tk466aTWRRdd1Lrjjjve2GbZsmWtiGgtW7Zsv59dd9116fv76U9/2po3b15r1KhRrREjRrTOOeec1o9//OMmpwx4k2N9Dmm1Wq3nn3++dckll7RGjx7d6unpaV100UWtNWvWvNNTBvwG8wiHSker9aZnYgAAABX4fzQAAIDqFBoAAEB1Cg0AAKA6hQYAAFCdQgMAAKhOoQEAAFSn0AAAAKrTGRzgTbLWQh0dHYdoJAf21FNPpdv86Z/+aTG/9NJLi/kZZ5xRzIcNG1bMhw4t/2p58skni/lPfvKTYh4RMWvWrGL+5m7EBzJ27Nj0GHA0euWVV4r597///XQfl112WTGfPHnywQzpkFu5cmW6zapVq4r5Jz7xiWLe2dl5MEM6bnmiAQAAVKfQAAAAqlNoAAAA1Sk0AACA6hQaAABAdQoNAACgOoUGAABQXUcrWzQe4CjRznQ22H0wHn300WJ+++23F/M777yzmA8ZMiQdQ39/fzHfuXNnMd+8eXN6jMF06qmnptuccEL538myNfKzPgALFiwo5p/97GeL+Zw5c4o5vFPZ/X3bbbcV869//evpMbJeOb29vY1en/WgyN7jwMBAMX/++eeLeUTEokWLivkHPvCBYv7JT34yPQaeaAAAAINAoQEAAFSn0AAAAKpTaAAAANUpNAAAgOoUGgAAQHUKDQAAoDp9NADeZNu2bcX8sssuK+aPPfZYMc+m3J6enmI+fPjwYh4RMXTo0GKe9eLYu3dvMd+6dWsxHzFiRKPjD3avk4iIXbt2FfOs18ju3buL+bnnnlvMf/jDHxZzeKf++Z//uZi3M4f81V/9VTFft25dMV+/fn0xz/pgjB07tpiPGjWqmH/kIx8p5hERv//7v1/Ms14eWR8Ofs0TDQAAoDqFBgAAUJ1CAwAAqE6hAQAAVKfQAAAAqlNoAAAA1Sk0AACA6sqLrXPEydbgb7r+/Pbt24v5/fffX8wXLlzY6PgR+Xv8v//7v2Ke9RA4FJq2pzkUfQQ4sMWLFxfz5557rphPmjSpmGefbXZ9Zz0o2pEdI7t+J0yY0Gj/mUPR3inrJdDd3V3Ms8/xvvvuK+ZPPfVUMY+IOO2009Jt4Dc17VEREXHVVVcV829+85vFvKurq5g3HeP73//+Yv7pT3+6mEdE9PX1FfPe3t50H+Q80QAAAKpTaAAAANUpNAAAgOoUGgAAQHUKDQAAoDqFBgAAUJ1CAwAAqE6hAQAAVHf4O5txUPbt21fMs2ZeTz/9dDH/7ne/W8yzJlcjR44s5hF5I6x58+YV86YN+bJmYNk5bqeZWNMxHoqmbcerFStWFPOsId+JJ55YzPfu3XvQY3qznTt3FvMXX3yx8T6yazy7frPr84QTmv0b1u7du9NtOjs7i/moUaOK+bRp04p503s4OwfZXBsRsWTJkkZj4PiUXfsbN25M9zFz5sxinl2b2Ty1YcOGYv6ud72rmGfzcDvvMZurD0Xj0OOBJxoAAEB1Cg0AAKA6hQYAAFCdQgMAAKhOoQEAAFSn0AAAAKpTaAAAANXpo3GUadpfYenSpcX8nnvuKebTp08v5gMDA8U8IuK1114r5j/72c+K+RVXXFHMJ02aVMw7OjqKeY0eFf39/cU8W2N/xIgRjcfAgS1btqyYZ9fwrl27inn22WY9LLq6uor53/7t3xbziIgpU6YU8+w+XrduXaP9Z+8x64HRTh+N7B575JFHivk3vvGNYt7b21vM9+zZU8yz6+DOO+8s5hH6aPDO1PgdtmnTpkavz/pcTJ48uZhn3xOyPh3tnIPsu0CW0x5PNAAAgOoUGgAAQHUKDQAAoDqFBgAAUJ1CAwAAqE6hAQAAVKfQAAAAqtNH4ygzbNiwRq9/6KGHinlfX18xz9bHz/KIiN/93d8t5o8++mgx//znP1/M586dW8znzJlTzE877bRivnz58mIekZ/n+fPnF/MPfOADxXzMmDHpGDiwO+64o5hn669n1/jQoeVpNVsfPvtssz4yEXkvmhUrVhTzP/qjPyrmN998czF/73vfW8yzXiRZv6CIiIkTJxbzz3zmM8X8O9/5TjHP+mRk72HkyJHFfNWqVcU8ImL16tXF/NRTT033wfGn1WoV83b6Q2TzYHaPbtmyJT3GYMrOQUR+Hvbu3VtrOMc1TzQAAIDqFBoAAEB1Cg0AAKA6hQYAAFCdQgMAAKhOoQEAAFSn0AAAAKrTR+MI03T963vuuaeYP/zww8V89OjRxXzHjh3FPFv3vZ1tzjrrrGJ+8sknF/P+/v5i/otf/KKY33XXXcU865MQETFv3rxifssttxTzrF/KBRdckI6BA3vssceK+fTp04t5tn78wMDAQY/pzbZu3dro9RERCxYsKOY9PT3F/KmnnirmN9xwQzFfvHhxMf+3f/u3Yt7O+vVnnHFGMX/kkUeKedN+JyecUP53uizPrrOIiAceeKCY66PBgWS/A9uZo7q7u4t5Ng9m13/2+nb6YJS009Mr2ybrlUN7PNEAAACqU2gAAADVKTQAAIDqFBoAAEB1Cg0AAKA6hQYAAFCdQgMAAKhOH42Kmq77XMOXvvSlYv7SSy812n+2tvyQIUPSfXR1dRXz+++/v5hnvUCyXiNnnnlmMT/llFOKeTvv8Vvf+lYxf/bZZ4v5nXfemR6D/f33f/93uk1vb28xzz7fbP33LN+5c2cxHz9+fDFvx5NPPlnMs3swmyf+4i/+ophnc2FnZ2ej10fkPSYyU6ZMKebr1q0r5tl1ks1Dw4cPL+YRET//+c+L+eWXX57ug+NP1oemnfsr2ybrQZG9frD3306/q+wY2VxOezzRAAAAqlNoAAAA1Sk0AACA6hQaAABAdQoNAACgOoUGAABQnUIDAACoTh+NirJ10w+FcePGFfNsffxsbfeBgYFivmfPnmIeEdHf31/Mu7u7i3nWhyD7HLI+Hb/4xS+KeTtrkK9fv76Yf/SjH033wcG7/vrr022y62fkyJHFPFufPes1k13fWY+JrI9MRMSmTZuK+ebNm4t5dh9n13f2HrJzsHv37mIeEbFly5ZifvvttxfzV199tZhnc2F2/Oz17cyVK1asSLeB35T1hxgxYkS6j6yHRNM+F+30oyqp8X0r6ydEHZ5oAAAA1Sk0AACA6hQaAABAdQoNAACgOoUGAABQnUIDAACoTqEBAABUp4/GMSZbw7/p2tjZ2vCTJ08u5hEREyZMKOZ9fX3F/IQTyvVxtn53dg6yPgvZ8SPyNcJfeOGFdB8cvPnz56fbZD0gnn766WK+devWYp7dg6ecckoxz66vs88+u5hH5Ndfdowsz+aJrEdEdo9mvUoi8vt49OjRxfzUU08t5jt27CjmTfsITJ06tZhHRCxatCjdBn5Tdm22I7u/sjmi6XeNpvbu3Ztuk/XRyH5X0B5PNAAAgOoUGgAAQHUKDQAAoDqFBgAAUJ1CAwAAqE6hAQAAVKfQAAAAqlNoAAAA1WnYV1HWoKmdBjVZo63+/v5ivm7dumKeNagZNmxYMd+9e3ej/UdEjBw5sphnDdGyhn9Zw7TsPfT09BTzbdu2FfOIiDlz5hTzrBnYww8/XMznzp2bjuF4dOWVVzbe5tVXXy3ma9asKeY33XRTMb/33nuL+fjx44t5dm1FRIwdO7aYZ/fAYDfTymRzaUQ+xu7u7mKezTOnn356Mf/Rj35UzGGwZHNU1iyvnfuro6OjmB/uOSJrGNhOw75sjsi+S+zatavR/o8XnmgAAADVKTQAAIDqFBoAAEB1Cg0AAKA6hQYAAFCdQgMAAKhOoQEAAFSnj0ZF2brT2drWEXkfjdtvv72Yv/TSS8W8t7e3mO/cubOYZ+PL+kNERDz33HPFvLOzs5gPDAwU86FDy5f1nj17inl2DjZu3FjMIyKuuuqqYr5y5cpi3s4a4AyOcePGFfN58+YV86yXzNKlS4t5No9k139Efh9m11e2Rn0mW6c/y9s5fnYesnkkWwN//vz56RjgcMjmmCzP5pgamh6jRl+yTPadbMyYMcVcn4z2eKIBAABUp9AAAACqU2gAAADVKTQAAIDqFBoAAEB1Cg0AAKA6hQYAAFCdPhoVZWvTDxs2rPEx3ve+9xXzbP3srIdEtq501kfjlVdeKeYR+drT48ePL+bZec7eY9ZjIOujMH369GIeEfGjH/2omH/uc58r5uecc056DN6ZbH327PrJ7uNs/fhRo0YV86b3YDtjyGTn6FCsw99U03X2x44d2+j12efYTq+Qo+E8c+jV6Nl1rGvn3mmnJxHNeaIBAABUp9AAAACqU2gAAADVKTQAAIDqFBoAAEB1Cg0AAKA6hQYAAFDdIeujka3L3s66z9m66NkxOjs7i3k765qXDB06+Kdz4cKFxbynp6eYDx8+vJjv3r37oMf0Zr29vek2WR+MXbt2FfOm/Uiyzym7Dtq5Vh9//PFiPmbMmHQfDI5sffVsnsjMnj27mI8ePbqYH4p+PNk5OBr6aGTnoelc1vQezX5ftdMPBQ6kaZ+Mdr7rNO1D03QMg338do6R3aPZ65t+pzxWOAsAAEB1Cg0AAKA6hQYAAFCdQgMAAKhOoQEAAFSn0AAAAKpTaAAAANVVa/yQreucrUd8KHpQDLaf//znxfzOO+9M93H//fcX8xEjRhTzCRMmFPOBgYFinq2Pn31O2fgi8mslG2PWZyN7DyNHjizmmXbW58+OcddddxXziy+++KDGRD1N11bPetV0dXUV8+z6bqfPx549e4p50z4Z2euzvMYa+d3d3cX8tddeK+bZGPW54EjV9HdgO31wmt4f2T3etBdIJht/RPPzlH0XyOao44UnGgAAQHUKDQAAoDqFBgAAUJ1CAwAAqE6hAQAAVKfQAAAAqlNoAAAA1VVrXnEo1hzfvHlzMV+3bl0xX716daPXZ70Psv1n6+dH5GtPZ/0ZNm3aVMynTp1azLN1n7P1+devX1/MI/LzkK1/P3/+/GK+ffv2Yn7fffcV8xNOKNffY8aMKeYRea+DX/7yl+k+ODzaWWO+JLt+svxQrIGfyY7RtA9G0z4c7cjOc7aOf/b6TNPrCN5O0/unRo+JTI17eLA1HWONfkDHA080AACA6hQaAABAdQoNAACgOoUGAABQnUIDAACoTqEBAABUp9AAAACqq9ZH44EHHijmX/7yl4v5hg0b0mNs2bKlmGfrnmdrHo8dO7aYZ71CRo0aVczb6aORres8fPjwYp71mLj99tuL+VlnnVXMt23bVsyzPhwREX19fek2JY8//ngx7+/vL+bTpk0r5lmvkqzPR0TEjh07innTc8DRK+vXk81DWf+HdhyKPhaDLRtj1ssme/3evXsPekxwKNSYAwZb1oej6RyTvb6dPiDZPZ6dZ3NEezzRAAAAqlNoAAAA1Sk0AACA6hQaAABAdQoNAACgOoUGAABQnUIDAACoTqEBAABU13bDvqxxydVXX13MsyZVQ4fmQ8ka8mWN1jIDAwPFPGuWl+Xt2Lp1azH/3//932L+hS98oZhnY7zpppuK+ZQpU4p5Ow37LrjggmI+e/bsYr5mzZpivmnTpmKeNfLKmvBkjR8j8ut54sSJ6T44PNpp9NRE1vgzs3v37nSbbK5s2rCvabOsGs22svOQNUjNjtG0GddgX0ccv7L7J5tj2rk2s2O083uw6RiavL7p+CLyc5B9Xxs9enTjMRwLPNEAAACqU2gAAADVKTQAAIDqFBoAAEB1Cg0AAKA6hQYAAFCdQgMAAKiu7T4at956azHP+jvMmjWrmO/YsSMdw/bt24t51j8hk62bnq2ZPG3atGJ+0kknpWPYuXNnMZ80aVIxv/zyy4v53XffXcwvvvjiYr527dpi3s7nuGLFimK+bNmyYp71dMnWz8/6pbTTpyCT9dHIjvH8888X8+nTpx/0mDgyZNdntv57O304sn1kfTaa9pjIetVk+8/u8Xb20U5vppItW7Y0ej0Mlj179hTz7P7P+kO0o0YvnMMtmyOy97Br166awzlmeaIBAABUp9AAAACqU2gAAADVKTQAAIDqFBoAAEB1Cg0AAKA6hQYAAFBd2wuNT5w4sZhnPSSyHhjZ2vIRETNmzGh0jGzt6W3bthXz8ePHF/OZM2cW82x8ERHd3d2N8myN/cWLFxfzOXPmFPO+vr5i3k4vk+yzHjt2bDHP1ujPzsGwYcOKedbjIutBEJGvMZ7lq1evLub6aBy92umD0dRgr3Gf9blo2sOinfE1fY/ZPJL1NMocDX0EODplfWyye6NGn5ojXdM5KCKfI2r0IzkeeKIBAABUp9AAAACqU2gAAADVKTQAAIDqFBoAAEB1Cg0AAKA6hQYAAFBd2wsNZ30yst4C2br/O3bsSMewYcOGYp71X+jt7W2UZ2tXDwwMNHp9RMSuXbuKeX9/fzHP1seeMGFCMf+f//mfYt7T01PMs14nERHjxo0r5tk5yD6nbP3sbG3s7PXtrK//8ssvF/MxY8YU85UrVxbzCy+8MB0DR6Z21rBvarDXwB/s9ePbGf++ffsa7SPrZ/Laa6+lY4DDIev1lGnn/sq+02X339Ggaa+ddr634okGAAAwCBQaAABAdQoNAACgOoUGAABQnUIDAACoTqEBAABUp9AAAACqa7uPxm//9m8X88WLFxfz733ve8V86tSp6Rhmz55dzLu7u4t51oMiW5s665+wZ8+eYt5OH43sPWT7yNaFHjFiRDGfMmVKMc/W1s7Wpo/I30PWD2X79u3FvKurq9H+s3zYsGHFPCJff3vt2rXFfNKkSekxGByD3YMicySsT9+0T0bTXiHtfAbZGLPzmPXLORT9TuCdyL6rZPdPdu1HDH6vnMHWzjyafV/Jfo8/88wzxfyMM85Ix3A88EQDAACoTqEBAABUp9AAAACqU2gAAADVKTQAAIDqFBoAAEB1Cg0AAKC6tvtoZK699tpinvXhuOGGG9JjZL0Hent7i3nWHyHrMZGtyzwwMFDM21mXPesxka1tna2fne2/aS+RdnqFNF2fO3t99jlmfTg2b95czLNeIhERL7/8cjE//fTTi/kf/MEfpMdgcDS9xzJZH5bsHqshu4azuS5bfz57fTv3UCb7HLLPMXsPh6IXCLwT69ata/T6dnpMZNdvdg9n90/T+6PGHJPNEVm/kRNPPDE9Bp5oAAAAg0ChAQAAVKfQAAAAqlNoAAAA1Sk0AACA6hQaAABAdQoNAACgurb7aDRds/hjH/tYozwiYunSpcU86+XR19dXzLdu3VrMszWXs3Wj9+zZU8wj8nWbszFMnDixmGdrV0+bNq2Yd3d3F/Oenp5iHtF8ffpM1qegab+U3/md30nHcNpppxXz+fPnp/vg+NS0h0VEPk9kx2iaZ78PmvbSicjnsnZ6BZQM9jwF71T2ezj7rtFOD4vs+j/cfWo6Ozsb7z+bp/r7+4v5jBkz0mPgiQYAADAIFBoAAEB1Cg0AAKA6hQYAAFCdQgMAAKhOoQEAAFSn0AAAAKpTaAAAANW13bAva2xyKFxwwQXF/Je//GWj/a9ataqYb9iwoZiPGzeumL/wwgvpGGbOnFnMs2Z0s2fPTo8BvL12mlk1MXXq1GK+Zs2aYp419YzI5+ss3717d6PXZ+cwy9t5j+00QG2iaUOxwb6OOH7NmzevmK9evbqYb9myJT1G1hQwkzX0y+7xQ3H/vPTSS8U8m+fe/e531xzOMevwVw8AAMAxR6EBAABUp9AAAACqU2gAAADVKTQAAIDqFBoAAEB1Cg0AAKC6jla22DEA1Vx44YXFfO3atcW8q6srPcamTZuKedYjYt++fcV8sHtYtNNHI3sP06ZNK+Y7d+4s5uedd14x/8EPflDMs3N4JPSm4ti0a9euYr5s2bJ0Hxs3bizmO3bsKOZ79+4t5p2dnekYSrL7v505JOtplPVuGzFiRHoMPNEAAAAGgUIDAACoTqEBAABUp9AAAACqU2gAAADVKTQAAIDqFBoAAEB1+ULDAMeRrLVQR0dHo/2feeaZxfy9731vMR87dmx6jKZ9LrIeED09PcU8O0fZOW5nDfysD0W2Tv+WLVuK+bx589IxlOiTwWDJ7p/u7u5ivnDhwsZj2Lx5czF/+eWXi/nWrVuLeTaHTJ48uVEekZ+nzGD/rjhWmAkBAIDqFBoAAEB1Cg0AAKA6hQYAAFCdQgMAAKhOoQEAAFSn0AAAAKrraGULAQMAABwkTzQAAIDqFBoAAEB1Cg0AAKA6hQYAAFCdQgMAAKhOoQEAAFSn0AAAAKpTaAAAANUpNAAAgOr+H2KZI9Vh5rFnAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get a batch of training data\n",
    "batch = next(iter(train_dataloader))\n",
    "images, labels = batch\n",
    "\n",
    "# plot the first three images in the batch\n",
    "fig, axs = plt.subplots(1, 3, figsize=(10, 5))\n",
    "for i in range(3):\n",
    "    axs[i].set_axis_off()\n",
    "    axs[i].imshow(images[i].squeeze(), cmap=plt.cm.gray_r)\n",
    "    axs[i].set_title(f\"Label: {labels[i]}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
